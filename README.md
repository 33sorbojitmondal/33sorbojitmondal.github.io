# Auto_Evaluazer


## Description

Automatic Long Answer Evaluation Model- It allows users to input a question and a model answer, alongside  student responses. The model meticulously grades the provided answers by comparing them to the model answer, leveraging advanced techniques such as sentiment analysis, word embeddings, and context matching. 

## Instructions for using the model:

Step 1:
Create virtual environment,activate it and install requirements

python -m venv myenv
myenv\Scripts\activate
pip install -r requirements.txt

Step 2:

python <filename>.py
use the paths of testdata_1.py,testdata_2.py,testdata_3.py for testing the models.

For app.py
python -m spacy download en_core_web_sm


## Authors
- [@Ricky](https://github.com/Ricky2054)
- [@Sorbojit](https://github.com/33sorbojitmondal)
- [@Ritika](https://github.com/Ritika3004)
- [@Sagarika](https://github.com/Sagarika-02)
